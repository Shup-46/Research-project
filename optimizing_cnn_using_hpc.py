# -*- coding: utf-8 -*-
"""Optimizing CNN using HPC

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_tphWb_kTKDDX3eJiN9nSU9jNwcZV5uQ
"""

import torch
torch.manual_seed(0)
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import time
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Load and preprocess the CIFAR-10 dataset
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
# batch_size = 256
trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)
testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=2)
classes =("plane", "car", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck")

#  Define the CNN architecture
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1)
        self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)
        self.fc1 = nn.Linear(4 * 4 * 64, 500)
        self.dropout1 = nn.Dropout(0.2)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv3(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4 * 4 * 64)
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = self.fc2(x)
        return x

# Initialize the CNN model, loss function and optimizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
net = Net().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

# Set the number of threads for OpenMP parallelization
torch.set_num_threads(4)

# Train the CNN model on the dataset using OpenMP and CUDA parallelization
start_time = time.time()
for epoch in range(4):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        optimizer.zero_grad()

        with torch.cuda.amp.autocast():
            outputs = net(inputs)
            loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 200 == 199:
            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))
            running_loss = 0.0

end_time = time.time()
print('Training time:', end_time-start_time, 'seconds')

# Test the model on the test dataset
net.eval()
test_loss = 0
y_true, y_pred = [], []
with torch.no_grad():
    for data in testloader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = net(images)
        test_loss += criterion(outputs, labels).item()
        _, predicted = torch.max(outputs.data, 1)
        y_true += labels.cpu().numpy().tolist()
        y_pred += predicted.cpu().numpy().tolist()

# Evaluate the model on the test set
net.eval()
with torch.no_grad():
    correct = 0
    total = 0
    true_positives = 0
    false_positives = 0
    false_negatives = 0
    for data in testloader:
        images, labels = data[0].to(device), data[1].to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        true_positives += ((predicted == labels) & (labels == 1)).sum().item()
        false_positives += ((predicted != labels) & (labels == 0)).sum().item()
        false_negatives += ((predicted != labels) & (labels == 1)).sum().item()

accuracy = 100 * correct / total
precision = 100 * true_positives / (true_positives + false_positives)
recall = 100 * true_positives / (true_positives + false_negatives)
f1_score = 2 * precision * recall / (precision + recall)

print('Accuracy: %.2f%%' % accuracy)
print('Precision: %.2f%%' % precision)
print('Recall: %.2f%%' % recall)
print('F1 score: %.2f%%' % f1_score)